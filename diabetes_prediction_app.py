# -*- coding: utf-8 -*-
"""diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HrkbE1KaCwl-roenhRcp3MWPaxVphGEe
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

df = pd.read_csv("diabetes.csv")
df.head()

df.info()

df.isna().sum()

df.dtypes

"""Exploratory Data Analysis and Visualisation


"""

sns.set(style="whitegrid", palette="Set2")

def freedman_bins(feature_name):
    iqr = df[feature_name].quantile(0.75) - df[feature_name].quantile(0.25)
    h = 2 * iqr / df.shape[0]**(1/3)
    num_bins = int((df[feature_name].max() - df[feature_name].min()) / h)
    return num_bins if num_bins <= 30 else 30

sns.countplot(x="diabetes", data=df)
plt.title("Distribution of Diabetes")
plt.xlabel("Diabetes")
plt.ylabel("Count")

"""Based on the chart, we can conclude that in the dataset there are more patients without diabetes.

Count plot for categorical features
"""

fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))

# Chart 1: Distribution of gender
sns.countplot(x="gender", data=df, ax=axes[0, 0])
axes[0, 0].set_title("Distribution of Gender")
axes[0, 0].set_xlabel("Gender")
axes[0, 0].set_ylabel("Count")

# Chart 2: Distribution of hypertension
sns.countplot(x="hypertension", data=df, ax=axes[0, 1])
axes[0, 1].set_title("Distribution of Hypertension")
axes[0, 1].set_xlabel("Hypertension")
axes[0, 1].set_ylabel("Count")

# Chart 3: Distribution of heart disease
sns.countplot(x="heart_disease", data=df, ax=axes[1, 0])
axes[1, 0].set_title("Distribution of Heart Disease")
axes[1, 0].set_xlabel("Heart Disease")
axes[1, 0].set_ylabel("Count")

# Chart 4: Distribution of smoking history
sns.countplot(x="smoking_history", data=df, ax=axes[1, 1])
axes[1, 1].set_title("Distribution of Smoking History")
axes[1, 1].set_xlabel("Smoking History")
axes[1, 1].set_ylabel("Count")

plt.tight_layout()
plt.show()

"""Histogram for numerical features

"""

fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))

# Chart 4: Distribution of age
sns.histplot(data=df, x='age', bins=freedman_bins('age'), kde=True, ax=axes[0, 0], hue='diabetes')
axes[0, 0].set_title("Age Distribution")
axes[0, 0].set_xlabel("Age")
axes[0, 0].set_ylabel("Count")

# Chart 4: Distribution of bmi
sns.histplot(data=df, x='bmi', bins=freedman_bins('bmi'), kde=True, ax=axes[0, 1])
axes[0, 1].set_title("BMI Distribution")
axes[0, 1].set_xlabel("BMI")
axes[0, 1].set_ylabel("Count")

# Chart 4: Distribution of HbA1c_level
sns.histplot(data=df, x='HbA1c_level', bins=freedman_bins('HbA1c_level'), kde=True, ax=axes[1, 0])
axes[1, 0].set_title("HbA1c Level Distribution")
axes[1, 0].set_xlabel("HbA1c Level")
axes[1, 0].set_ylabel("Count")

# Chart 4: Distribution of blood glucose level
sns.histplot(data=df, x='blood_glucose_level', bins=freedman_bins('blood_glucose_level'), kde=True, ax=axes[1, 1])
axes[1, 1].set_title("Blood Glucose Level Distribution")
axes[1, 1].set_xlabel("Blood Glucose Level")
axes[1, 1].set_ylabel("Count")


plt.tight_layout()
plt.show()

"""Box plot Hypertension vs Age and Heart Disease vs Age"""

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))

# Chart 1: Box plot Hypertension vs Age
sns.boxplot(data=df, x='hypertension', y='age', ax=axes[0])
axes[0].set_title("Age distribution in hypertension")
axes[0].set_xlabel("Hypertension")
axes[0].set_ylabel("Age")

# Chart 2: Box plot Heart Disease vs Age
sns.boxplot(data=df, x='heart_disease', y='age', ax=axes[1])
axes[1].set_title("Age distribution in heart disease")
axes[1].set_xlabel("Heart Disease")
axes[1].set_ylabel("Age")

plt.tight_layout()
plt.show()

df.duplicated().sum()

""" there are 3854 duplicate rows in the DataFrame."""

df = df.drop_duplicates()

df.duplicated().sum()

"""Drop rows where gender is Other"""

df = df[df['gender'] != 'Other']

new_categories = {"never": "no", "No Info": "no", "current": "yes", "ever": "yes", "former": "ex", "not current": "ex"}
df['smoking_history'] = df['smoking_history'].map(new_categories)

df.head()

"""Grouping by bmi"""

bins = [0, 18.5, 24.9, 29.9, float('inf')]
labels = ['Under', 'normal', 'Over', 'Obese']


df['bmi'] = pd.cut(df['bmi'], bins=bins, labels=labels)

"""One-Hot-encoding in features gender, bmi and smoking_status"""

df = pd.get_dummies(df, columns=['gender', 'bmi', 'smoking_history'], prefix=['gender', 'bmi', 'smoking_history'])

""" Normalization of age, HbA1c_level and Blood glucose level"""

scaler = StandardScaler()
columns_to_normalize = ['age', 'HbA1c_level', 'blood_glucose_level']
df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])

df.head()

"""##Modeling"""

X = df.drop('diabetes', axis=1)
y = df['diabetes']

"""###Training"""

lr_model = LogisticRegression()
svc_model = SVC()
mlp_model = MLPClassifier()
nb_model = GaussianNB()
knn_model = KNeighborsClassifier()
gb_model = GradientBoostingClassifier()
dt_model = DecisionTreeClassifier()
sgd_model = SGDClassifier()
rf_model = RandomForestClassifier()
et_model = ExtraTreesClassifier()
xgb_model = XGBClassifier()


classifiers = {
    'Logistic Regression': lr_model,
    'SVM': svc_model,
    'MLPClassifier': mlp_model,
    'Naive Bayes': nb_model,
    'KNN': knn_model,
    'Gradient Boosting': gb_model,
    'Decision Tree': dt_model,
    'SGD': sgd_model,
    'Random Forest': rf_model,
    'Extra Tree': et_model,
    'XGBoost': xgb_model,
}

accuracy_scores = []
for name, clf in classifiers.items():
    mean_acc = 0
    for i, state in enumerate([10, 20, 30, 50, 100]):
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=state)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        mean_acc += accuracy
        print(f"{i} - Model: {name}; Acc: {accuracy}")
    mean_acc /= 5
    accuracy_scores.append((name, mean_acc))

"""### Evaluate Models"""

accuracy_scores.sort(key=lambda x: x[1], reverse=True)

df_accuracy = pd.DataFrame(accuracy_scores, columns=['Classifier', 'Accuracy'])

plt.figure(figsize=(10, 6))
# Define a color palette for the bar plot
colors = sns.color_palette("husl", len(df_accuracy))

sns.barplot(x='Accuracy', y='Classifier', data=df_accuracy, palette=colors)  # Specify the palette
plt.xlabel('Accuracy')
plt.ylabel('Classifier')
plt.title('Classifier Accuracy Comparison')
plt.xlim(0, 1.0)

for index, row in df_accuracy.iterrows():
    plt.text(row['Accuracy'] - 0.1, index, f'{row["Accuracy"]:.2%}', va='center', color='black')

plt.tight_layout()
plt.show()

accuracy_scores.sort(key=lambda x: x[1], reverse=True)

df_accuracy = pd.DataFrame(accuracy_scores, columns=['Classifier', 'Accuracy'])
df_accuracy_text = df_accuracy.to_string(index=False)  # Convert DataFrame to string

print(df_accuracy_text)

"""###Feature Importance"""

gb_feature_importance = gb_model.feature_importances_
xgb_feature_importance = xgb_model.feature_importances_

# Criar um DataFrame para visualização
feature_importance_df = pd.DataFrame({
    'Feature': X_train.columns,
    'GB_Importance': gb_feature_importance,
    'XGB_Importance': xgb_feature_importance
})

# Ordenar o DataFrame por importância combinada
feature_importance_df['Mean_Importance'] = (feature_importance_df['GB_Importance'] + feature_importance_df['XGB_Importance'])/2
feature_importance_df = feature_importance_df.sort_values(by='Mean_Importance', ascending=False)

print(feature_importance_df)

"""#Deployment"""

!pip install streamlit

import streamlit as st
import pickle
import pandas as pd

# Title of the app
st.title('Diabetes Prediction App')

# Example DataFrame loading - replace this with your actual data loading
# df = pd.read_csv('your_dataset.csv')

X = df.drop('diabetes', axis=1)
y = df['diabetes']

# One-hot encode categorical variables
df_encoded = pd.get_dummies(df, drop_first=True)

X = df_encoded.drop('diabetes', axis=1)
y = df_encoded['diabetes']

# Define classifiers
classifiers = {
    'Logistic Regression': LogisticRegression(),
    'SVM': SVC(),
    'MLPClassifier': MLPClassifier(),
    'Naive Bayes': GaussianNB(),
    'KNN': KNeighborsClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'Decision Tree': DecisionTreeClassifier(),
    'SGD': SGDClassifier(),
    'Random Forest': RandomForestClassifier(),
    'Extra Tree': ExtraTreesClassifier(),
    'XGBoost': XGBClassifier(),
}

# Scale the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Calculate accuracy scores
accuracy_scores = []

for name, clf in classifiers.items():
    mean_acc = 0
    for state in [10, 20, 30, 50, 100]:
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=state)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        mean_acc += accuracy
        print(f"Random State {state} - Model: {name}; Acc: {accuracy:.4f}")
    mean_acc /= 5
    accuracy_scores.append((name, mean_acc))

    # Save the trained model to a file
    with open(f'{name.replace(" ", "_").lower()}_model.pkl', 'wb') as model_file:
        pickle.dump(clf, model_file)

# Sort classifiers by accuracy
accuracy_scores.sort(key=lambda x: x[1], reverse=True)

# Create a DataFrame for accuracy scores
df_accuracy = pd.DataFrame(accuracy_scores, columns=['Classifier', 'Accuracy'])

# Plotting
plt.figure(figsize=(10, 6))
colors = sns.color_palette("husl", len(df_accuracy))
sns.barplot(x='Accuracy', y='Classifier', data=df_accuracy, palette=colors)

plt.xlabel('Accuracy')
plt.ylabel('Classifier')
plt.title('Classifier Accuracy Comparison')
plt.xlim(0, 1.0)

# Add accuracy values to the plot
for index, row in df_accuracy.iterrows():
    plt.text(row['Accuracy'] - 0.1, index, f'{row["Accuracy"]:.2%}', va='center', color='black')

plt.tight_layout()
plt.show()

import streamlit as st
import pickle
import pandas as pd

# Title of the app
st.title('Diabetes Prediction App')

# Load your trained model
try:
    model = pickle.load(open('model.pkl', 'rb'))
except FileNotFoundError:
    st.error("Model file not found. Please ensure 'model.pkl' is in the same directory as this script.")

# Create input fields for the features
age = st.number_input('Age', min_value=0, max_value=120, value=25)
bmi = st.number_input('BMI', min_value=0.0, max_value=70.0, value=25.0)
glucose = st.number_input('Glucose Level', min_value=0, max_value=300, value=100)
blood_pressure = st.number_input('Blood Pressure', min_value=0, max_value=200, value=80)
skin_thickness = st.number_input('Skin Thickness', min_value=0, max_value=100, value=20)
insulin = st.number_input('Insulin Level', min_value=0, max_value=900, value=80)
dpf = st.number_input('Diabetes Pedigree Function', min_value=0.0, max_value=2.5, value=0.5)
pregnancies = st.number_input('Number of Pregnancies', min_value=0, max_value=20, value=1)

# Predict button
if st.button('Predict'):
    # Create a DataFrame for the input values
    input_data = pd.DataFrame({
        'Pregnancies': [pregnancies],
        'Glucose': [glucose],
        'BloodPressure': [blood_pressure],
        'SkinThickness': [skin_thickness],
        'Insulin': [insulin],
        'BMI': [bmi],
        'DiabetesPedigreeFunction': [dpf],
        'Age': [age]
    })

# Predict the output
try:
    prediction = model.predict(input_data)[0]
    # Display the prediction
    st.write(f'The predicted diabetes status is: {"Positive" if prediction == 1 else "Negative"}')
except Exception as e:
    st.error(f"An error occurred during prediction: {e}")